# Sistema de Inteligencia de Precios - ConfiguraciÃ³n Actualizada

## Datos Proporcionados Integrados

Se han integrado exitosamente los siguientes archivos:

1. **ebay_agent_4.py** - Agente de web scraping de eBay con sesiÃ³n persistente usando Playwright
2. **thrift_sales_12_weeks_with_subcategory.csv** - Datos de ventas con 3,602 registros
3. **README (3).md** - DocumentaciÃ³n del agente eBay

## Cambios Realizados

### 1. Cliente eBay (`app/services/ebay_client.py`)
- âœ… Reemplazado por implementaciÃ³n con web scraping usando `ebay_agent_4`
- âœ… SesiÃ³n persistente del navegador para evitar bloqueos
- âœ… Soporte asÃ­ncrono con `async/await`
- âœ… Retorna datos de listings vendidos con estadÃ­sticas (median, avg, min, max)

### 2. Procesador de Datos Internos (`app/services/internal_data.py`)
- âœ… Adaptado al nuevo formato CSV con columnas:
  - `item_id`, `department`, `category`, `subcategory`
  - `brand`, `production_date`, `sold_date`, `days_to_sell`
  - `production_price`, `sold_price`
- âœ… BÃºsqueda por keywords (brand, category, subcategory)
- âœ… CÃ¡lculo automÃ¡tico de sell-through rate
- âœ… MÃ©tricas agregadas por categorÃ­a

### 3. API Principal (`app/main.py`)
- âœ… SesiÃ³n persistente de eBay en startup/shutdown
- âœ… BÃºsqueda por keywords en lugar de UPC directo
- âœ… Soporte asÃ­ncrono completo

### 4. Dependencias (`requirements.txt`)
- âœ… Agregado `playwright==1.40.0` para web scraping

## Estructura de Datos

### CSV de Ventas Internas
```csv
item_id,department,category,subcategory,brand,production_date,sold_date,days_to_sell,production_price,sold_price
1,Children,Shoes,Sneakers,Old Navy,2025-11-10,2025-12-23,43.0,6.84,4.63
2,Children,Bottoms,Jeans,Adidas,2025-11-09,2025-11-17,8.0,17.08,18.08
...
```

**EstadÃ­sticas:**
- Total registros: 3,602
- Items vendidos: ~2,700 (75% sell-through rate estimado)
- Departamentos: Mens, Womens, Children
- Marcas: Nike, Adidas, Columbia, Levi's, Patagonia, etc.

## InstalaciÃ³n y ConfiguraciÃ³n

### 1. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 2. Instalar navegadores de Playwright
```bash
playwright install chromium
```

### 3. Configurar variables de entorno (opcional)
```bash
cp .env.example .env
# Editar .env si es necesario
```

## Pruebas

### Prueba RÃ¡pida (Solo Datos Internos)
```bash
python test_integration.py --quick
```

### Prueba Completa (Con Scraping de eBay)
```bash
python test_integration.py
```
**âš ï¸ Advertencia:** AbrirÃ¡ un navegador y harÃ¡ scraping real de eBay.

### Ejecutar API
```bash
python -m app.main
# o
./start.sh
```

## Ejemplos de Uso

### 1. Prueba desde Python
```python
import asyncio
from app.services.ebay_client import eBayClient
from app.services.internal_data import InternalDataProcessor
from app.services.pricing_engine import PricingEngine

async def main():
    # Inicializar servicios
    ebay = eBayClient(headless=True)
    await ebay.start_session()
    
    internal = InternalDataProcessor("thrift_sales_12_weeks_with_subcategory.csv")
    engine = PricingEngine()
    
    # Buscar datos
    search_term = "Nike Sneakers"
    internal_data = internal.search_by_keywords(search_term)
    market_data = await ebay.get_market_pricing(search_term)
    
    # Generar recomendaciÃ³n
    recommendation = engine.generate_recommendation(
        upc=search_term,
        market_data=market_data,
        internal_data=internal_data
    )
    
    print(f"Precio recomendado: ${recommendation.recommended_price:.2f}")
    print(f"Confianza: {recommendation.confidence_score}/100")
    print(f"RazÃ³n: {recommendation.rationale}")
    
    await ebay.close_session()

asyncio.run(main())
```

### 2. Prueba desde API
```bash
curl -X POST http://localhost:8000/price-recommendation \
  -H "Content-Type: application/json" \
  -d '{
    "upc": "Nike Air Max 90",
    "internal_data": null
  }'
```

## Algoritmo de Precios

El motor de recomendaciÃ³n considera:

1. **Sell-through rate interno**
   - \> 0.7 â†’ Mayor peso a precio interno (estÃ¡ funcionando)
   - < 0.7 â†’ Considerar ajuste

2. **Days on shelf**
   - \> 60 dÃ­as â†’ Reducir precio
   - < 30 dÃ­as â†’ Precio estÃ¡ bien

3. **Market sample size**
   - < 5 â†’ Baja confianza, mayor peso a interno
   - \> 10 â†’ Alta confianza en mercado

4. **VariaciÃ³n de precio**
   - Diferencia > 30% â†’ Investigar, posible outlier
   - Ajustar por categorÃ­a

5. **CategorÃ­as**
   - Diferentes mÃ¡rgenes por tipo de producto
   - MÃ©tricas histÃ³ricas por categorÃ­a

## Notas Importantes

### Web Scraping de eBay
- â±ï¸ Incluye delays aleatorios (2-4 segundos) entre bÃºsquedas
- ğŸ” Usa User-Agent personalizado
- ğŸŒ SesiÃ³n persistente para evitar detecciÃ³n
- âš ï¸ No abusar del scraping (respetar tÃ©rminos de servicio)

### Datos Internos
- ğŸ“Š 3,602 registros de 12 semanas de ventas
- ğŸ·ï¸ Sin UPCs directos â†’ bÃºsqueda por keywords
- ğŸ” BÃºsqueda flexible por brand/category/subcategory
- ğŸ’¾ Carga en memoria al inicio

### Rendimiento
- ğŸš€ Cache de resultados de eBay (configurable TTL)
- âš¡ SesiÃ³n persistente evita reinicio de navegador
- ğŸ“¦ Procesamiento de datos internos optimizado con pandas

## Troubleshooting

### Error: "playwright not installed"
```bash
playwright install chromium
```

### Error: "No module named 'ebay_agent_4'"
- Verificar que `ebay_agent_4.py` estÃ© en el directorio raÃ­z
- Verificar que el import path sea correcto

### Error: "CSV file not found"
- Verificar que `thrift_sales_12_weeks_with_subcategory.csv` estÃ© en el directorio raÃ­z
- O especificar path completo en InternalDataProcessor

### eBay scraping bloqueado
- Usar `headless=False` para ver quÃ© pasa
- Aumentar delays entre requests
- Verificar User-Agent
- Considerar usar proxies rotantes

## PrÃ³ximos Pasos

- [ ] Agregar mapping de UPC a producto (si se obtienen UPCs reales)
- [ ] Implementar rate limiting mÃ¡s sofisticado
- [ ] Agregar mÃ¡s fuentes de market data (Amazon, Mercado Libre, etc.)
- [ ] Dashboard para visualizaciÃ³n de decisiones
- [ ] A/B testing de algoritmos de pricing
- [ ] Machine Learning para predicciÃ³n de sell-through

## Contacto

Para preguntas o issues, revisar los logs en `logs/` o consultar la documentaciÃ³n de la API en `/docs`.
